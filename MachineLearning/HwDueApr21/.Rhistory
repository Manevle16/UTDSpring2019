apply(net['net.result'], 1, round)
# Apply the round function to the predicted values so you only 0s and 1s as your predicted classes.
apply(predictions['net.result'], 1, round)
# Apply the round function to the predicted values so you only 0s and 1s as your predicted classes.
apply(predictions, 1, round)
# Apply the round function to the predicted values so you only 0s and 1s as your predicted classes.
apply(predictions, 1, round)
dim(predictions)
dim(predictions['net.result'])
predictions[,1]
predictions[,2]
predictions[2]
dim(predictions[2])
predictions <- predictions[2]
View(predictions)
View(predictions)
dim(predictions[1])
predictions[1]
predictions[,1]
predictions[1,]
predictions <- data.frame(predictions)
dim(predictions)
# Apply the round function to the predicted values so you only 0s and 1s as your predicted classes.
apply(predictions, 1, round)
# Use table() to create a confusion matrix of your predictions versus the real values
table(predictions[,1], test$class)
# Apply the round function to the predicted values so you only 0s and 1s as your predicted classes.
predictions <- apply(predictions, 1, round)
# Use table() to create a confusion matrix of your predictions versus the real values
table(predictions[,1], test$class)
# Use table() to create a confusion matrix of your predictions versus the real values
table(predictions, test$class)
# Comparing Models
# Call the randomForest library
library(randomForest)
# set the Class column of the data as a factor (randomForest needs it to be a factor,
# not an int like neural nets did. Then re-do the train/test split
test$class <- factor(test$class)
# Create a randomForest model with the new adjusted training data.
tree <- randomForest(class ~ ., data=train, importance=TRUE)
# Create a randomForest model with the new adjusted training data.
tree <- randomForest(class ~ ., data=train)
# Use predict() to get the predicted values from your rf model.
treePredict <- predict(tree, test)
# Use table() to create the confusion matrix.
table(treePredict, test$class)
treePredict <- apply(treePredict, 1, round)
# Use predict() to get the predicted values from your rf model.
treePredict <- data.frame(predict(tree, test))
treePredict <- apply(treePredict, 1, round)
# Use table() to create the confusion matrix.
table(treePredict, test$class)
install.packages("neuralnet")
# Get the Data
# Use read.csv to read the bank_note_data.csv file.
df <- read.csv('bank_note_data.csv')
setwd("D:/GitHub/UTDSpring2019/MachineLearning/HwDueApr21")
df <- read.csv('Heart.csv')
# Check the head of the data frame and its structure.
head(df)
# EDA
# Create whatever visualizations you are interested in.
# the data isn't easily interpretable since its just statistical info on images.
pairs(df)
# Train Test Split
# Use the caTools library to split the data into training and testing sets.
library(caTools)
library(dplyr)
split = sample.split(df$variance, SplitRatio = 0.70)
train = subset(df, split == TRUE)
test = subset(df, split == FALSE)
# Check the head of the data frame and its structure.
head(df)
df <- df[,-1]
# Check the head of the data frame and its structure.
head(df)
split = sample.split(df$variance, SplitRatio = 0.70)
train = subset(df, split == TRUE)
split = sample.split(df$Age, SplitRatio = 0.70)
train = subset(df, split == TRUE)
test = subset(df, split == FALSE)
# Building the Neural Net
# Call the neuralnet library
library(neuralnet)
# Browse through the documentation of neuralnet
help("neuralnet")
# Use the neuralnet function to train a neural net, set linear.output=FALSe and choose
# 10 hidden neurons (hidden=10)
n <- names(train)
n
# Paste together
f <- as.formula(paste("AHD ~", paste(n[!n %in% "AHD"], collapse = " + ")))
f
net <- neuralnet(f, data=train, hidden=10, linear.output = FALSE)
# Get the Data
# Use read.csv to read the bank_note_data.csv file.
df <- read.csv('Heart.csv')
df <- df[,c(-1, -4, -14) ]
# EDA
# Create whatever visualizations you are interested in.
# the data isn't easily interpretable since its just statistical info on images.
pairs(df)
split = sample.split(df$Age, SplitRatio = 0.70)
train = subset(df, split == TRUE)
test = subset(df, split == FALSE)
# Use the neuralnet function to train a neural net, set linear.output=FALSe and choose
# 10 hidden neurons (hidden=10)
n <- names(train)
n
# Paste together
f <- as.formula(paste("AHD ~", paste(n[!n %in% "AHD"], collapse = " + ")))
f
net <- neuralnet(f, data=train, hidden=10, linear.output = FALSE)
# Get the Data
# Use read.csv to read the bank_note_data.csv file.
df <- read.csv('Heart.csv', stringsAsFactors=FALSE)
df <- df[,c(-1, -4, -14) ]
split = sample.split(df$Age, SplitRatio = 0.70)
train = subset(df, split == TRUE)
test = subset(df, split == FALSE)
# Use the neuralnet function to train a neural net, set linear.output=FALSe and choose
# 10 hidden neurons (hidden=10)
n <- names(train)
n
# Paste together
f <- as.formula(paste("AHD ~", paste(n[!n %in% "AHD"], collapse = " + ")))
f
net <- neuralnet(f, data=train, hidden=10, linear.output = FALSE)
library(MASS)
data <- Boston
str(data)
head(data)
View(data)
net <- neuralnet(f, data=train, hidden=3, linear.output = FALSE)
# Browse through the documentation of neuralnet
help("neuralnet")
net <- neuralnet(f, data=train, hidden=3, linear.output = FALSE, threshold = .01)
df$AHD <- factor(df$AHD)
levels(df$AHD)
as.numeric(df$AHD)
df$AHD <- as.numeric(df$AHD)
split = sample.split(df$Age, SplitRatio = 0.70)
train = subset(df, split == TRUE)
test = subset(df, split == FALSE)
net <- neuralnet(f, data=train, hidden=10, linear.output = FALSE, threshold = .01)
# EDA
# Create whatever visualizations you are interested in.
# the data isn't easily interpretable since its just statistical info on images.
pairs(df)
anyNA(df)
is.na(df)
subset(df, is.na(df) == TRUE)
subset(df, is.na(df) == FALSE)
df <- subset(df, is.na(df) == FALSE)
split = sample.split(df$Age, SplitRatio = 0.70)
train = subset(df, split == TRUE)
test = subset(df, split == FALSE)
# Get the Data
# Use read.csv to read the bank_note_data.csv file.
df <- read.csv('Heart.csv', stringsAsFactors=FALSE)
# Check the head of the data frame and its structure.
head(df)
df <- df[,c(-1, -4, -14) ]
df$AHD <- factor(df$AHD)
df <- subset(df, is.na(df) == FALSE)
split = sample.split(df$Age, SplitRatio = 0.70)
train = subset(df, split == TRUE)
test = subset(df, split == FALSE)
net <- neuralnet(f, data=train, hidden=10, linear.output = FALSE, threshold = .01)
# Get the Data
# Use read.csv to read the bank_note_data.csv file.
df <- read.csv('Heart.csv', stringsAsFactors=FALSE)
df <- df[,c(-1, -4, -14) ]
df$AHD <- factor(df$AHD)
df$AHD <- as.numeric(df$AHD)
df <- subset(df, is.na(df) == FALSE)
split = sample.split(df$Age, SplitRatio = 0.70)
train = subset(df, split == TRUE)
test = subset(df, split == FALSE)
# Use the neuralnet function to train a neural net, set linear.output=FALSe and choose
# 10 hidden neurons (hidden=10)
n <- names(train)
n
# Paste together
f <- as.formula(paste("AHD ~", paste(n[!n %in% "AHD"], collapse = " + ")))
f
net <- neuralnet(f, data=train, hidden=10, linear.output = FALSE, threshold = .01)
anyNA(df)
> which(is.na(df), arr.ind=TRUE)
which(is.na(df), arr.ind=TRUE)
View(df)
# Get the Data
# Use read.csv to read the bank_note_data.csv file.
df <- read.csv('Heart.csv', stringsAsFactors=FALSE)
View(df)
# Check the head of the data frame and its structure.
head(df)
df <- df[,c(-1, -4, -14) ]
df$AHD <- factor(df$AHD)
anyNA(df)
df <- subset(df, is.na(df) == TRUE)
# Get the Data
# Use read.csv to read the bank_note_data.csv file.
df <- read.csv('Heart.csv', stringsAsFactors=FALSE)
# Check the head of the data frame and its structure.
head(df)
subset(df, is.na(df) == TRUE)
df <- subset(df, is.na(df) == FALSE)
df <- df[,c(-1, -4, -14) ]
df$AHD <- factor(df$AHD)
which(is.na(df), arr.ind=TRUE)
# Get the Data
# Use read.csv to read the bank_note_data.csv file.
df <- read.csv('Heart.csv')
df <- df[,c(-1, -4, -14) ]
anyNA(df)
which(is.na(df), arr.ind=TRUE)
df <- subset(df, is.na(df$Ca) == FALSE)
which(is.na(df), arr.ind=TRUE)
anyNA(df)
split = sample.split(df$Age, SplitRatio = 0.70)
train = subset(df, split == TRUE)
test = subset(df, split == FALSE)
# Use the neuralnet function to train a neural net, set linear.output=FALSe and choose
# 10 hidden neurons (hidden=10)
n <- names(train)
n
# Paste together
f <- as.formula(paste("AHD ~", paste(n[!n %in% "AHD"], collapse = " + ")))
f
net <- neuralnet(f, data=train, hidden=10, linear.output = FALSE, threshold = .01)
net <- neuralnet(f, data=train, hidden=10, linear.output = FALSE)
# Predictions
# Use compute() to grab predictions useing your nn model on the test set.
predictions <- compute(net, test[, -12])
# Check the head of the predicted values. You should notice that they are still probabilities.
head(predictions)
max(predictions)
max(predictions[2])
predictions <- predictions[2]
predictions <- data.frame(predictions)
# Predictions
# Use compute() to grab predictions useing your nn model on the test set.
predictions <- compute(net, test[, -12])
predictions.nn.values
max(predictions$net.result)
levels(df$AHD)
levels(df$AHD) <- c(0, 1)
df <- subset(df, is.na(df$Ca) == FALSE)
which(is.na(df), arr.ind=TRUE)
anyNA(df)
split = sample.split(df$Age, SplitRatio = 0.70)
train = subset(df, split == TRUE)
test = subset(df, split == FALSE)
net <- neuralnet(f, data=train, hidden=10, linear.output = FALSE)
# Predictions
# Use compute() to grab predictions useing your nn model on the test set.
predictions <- compute(net, test[, -12])
# Check the head of the predicted values. You should notice that they are still probabilities.
head(predictions)
str(predictions)
# EDA
# Create whatever visualizations you are interested in.
# the data isn't easily interpretable since its just statistical info on images.
pairs(df)
# Get the Data
# Use read.csv to read the bank_note_data.csv file.
df <- read.csv('Heart.csv')
# Check the head of the data frame and its structure.
head(df)
df <- df[,c(-1, -4, -14) ]
df <- subset(df, is.na(df$Ca) == FALSE)
which(is.na(df), arr.ind=TRUE)
anyNA(df)
split = sample.split(df$Age, SplitRatio = 0.70)
train = subset(df, split == TRUE)
test = subset(df, split == FALSE)
# Paste together
f <- as.formula(paste("AHD ~", paste(n[!n %in% "AHD"], collapse = " + ")))
net <- neuralnet(f, data=train, hidden=10, linear.output = FALSE)
# Predictions
# Use compute() to grab predictions useing your nn model on the test set.
predictions <- compute(net, test[, -12])
# Check the head of the predicted values. You should notice that they are still probabilities.
head(predictions)
levels(df$AHD) <- c(0, 1)
# Apply the round function to the predicted values so you only 0s and 1s as your predicted classes.
predictions <- apply(predictions, 1, round)
# Apply the round function to the predicted values so you only 0s and 1s as your predicted classes.
predictions <- data.frame(predictions$net.result)
predictions <- apply(predictions, 1, round)
levels(test$AHD) <- c(0, 1)
# Use table() to create a confusion matrix of your predictions versus the real values
table(predictions, test$AHD)
View(predictions)
# Get the Data
# Use read.csv to read the bank_note_data.csv file.
df <- read.csv('Heart.csv')
df <- df[,c(-1, -4, -14) ]
df$AHD <- factor(df$AHD)
df$AHD <- as.numeric(df$AHD)
df$AHD[df$AHD == 1]
df$AHD[df$AHD == 1] <- 0
df$AHD[df$AHD == 2] <- 1
df <- subset(df, is.na(df$Ca) == FALSE)
which(is.na(df), arr.ind=TRUE)
anyNA(df)
split = sample.split(df$Age, SplitRatio = 0.70)
train = subset(df, split == TRUE)
test = subset(df, split == FALSE)
net <- neuralnet(f, data=train, hidden=10, linear.output = FALSE)
# Predictions
# Use compute() to grab predictions useing your nn model on the test set.
predictions <- compute(net, test[, -12])
# Check the head of the predicted values. You should notice that they are still probabilities.
head(predictions)
# Apply the round function to the predicted values so you only 0s and 1s as your predicted classes.
predictions <- data.frame(predictions$net.result)
# Use table() to create a confusion matrix of your predictions versus the real values
table(predictions, test$AHD)
# Use table() to create a confusion matrix of your predictions versus the real values
table(predictions[,1], test$AHD)
predictions <- apply(predictions, 1, round)
# Use table() to create a confusion matrix of your predictions versus the real values
table(predictions, test$AHD)
net <- neuralnet(f, data=train, hidden=c(5, 5), linear.output = FALSE)
# Predictions
# Use compute() to grab predictions useing your nn model on the test set.
predictions <- compute(net, test[, -12])
# Apply the round function to the predicted values so you only 0s and 1s as your predicted classes.
predictions <- data.frame(predictions$net.result)
predictions <- apply(predictions, 1, round)
# Use table() to create a confusion matrix of your predictions versus the real values
table(predictions, test$AHD)
net <- neuralnet(f, data=train, hidden=6, linear.output = FALSE)
# Predictions
# Use compute() to grab predictions useing your nn model on the test set.
predictions <- compute(net, test[, -12])
# Check the head of the predicted values. You should notice that they are still probabilities.
head(predictions)
str(predictions)
# Apply the round function to the predicted values so you only 0s and 1s as your predicted classes.
predictions <- data.frame(predictions$net.result)
# Predictions
# Use compute() to grab predictions useing your nn model on the test set.
predictions <- compute(net, test[, -12])
net <- neuralnet(f, data=train, hidden=10, linear.output = FALSE)
# Predictions
# Use compute() to grab predictions useing your nn model on the test set.
predictions <- compute(net, test[, -12])
# Apply the round function to the predicted values so you only 0s and 1s as your predicted classes.
predictions <- data.frame(predictions$net.result)
predictions <- apply(predictions, 1, round)
# Use table() to create a confusion matrix of your predictions versus the real values
table(predictions, test$AHD)
# Comparing Models
# Call the randomForest library
library(randomForest)
# set the Class column of the data as a factor (randomForest needs it to be a factor,
# not an int like neural nets did. Then re-do the train/test split
test$AHD <- factor(test$AHD)
# Create a randomForest model with the new adjusted training data.
tree <- randomForest(AHD ~ ., data=train)
train$AHD <- factor(train$AHD)
# Create a randomForest model with the new adjusted training data.
tree <- randomForest(AHD ~ ., data=train)
# Use predict() to get the predicted values from your rf model.
treePredict <- data.frame(predict(tree, test))
treePredict <- apply(treePredict, 1, round)
# Use table() to create the confusion matrix.
table(treePredict, test$AHD)
# Use predict() to get the predicted values from your rf model.
treePredict <- predict(tree, test)
# Use table() to create the confusion matrix.
table(treePredict, test$AHD)
read.csv('titanic.csv')
df <- read.csv('titanic.csv')
library(dplyr)
is.na(df['pclass'])
impute_age <- function(age,class){
out <- age
for(i in 1:length(age)){
if(is.na(age[i])){
if(class[i] == 1){
out[i] <- 37
}else if(class[i] == 2){
out[i] <- 29
}else{
out[i] <- 24
}
}else{
out[i]<-age[i]
}
}
return(out)
}
df[is.na(df['pclass']),]
df <- df[-1310,]
df[is.na(df['fare']),]
df <- df[-1226,]
fixed.ages <- impute_age(df$age, df$pclass)
df <- subset(df, select = -c(name, body, boat, home.dest, cabin, ticket))
df$sex <- factor(df$sex)
df$sex <- as.numeric(df$sex)
df$embarked <- factor(df$embarked)
df$embarked <- as.numeric(df$embarked)
# EDA
# Create whatever visualizations you are interested in.
# the data isn't easily interpretable since its just statistical info on images.
pairs(df)
df$sex[df$sex == 1] <- 0
df$sex[df$sex == 2] <- 1
df <- read.csv('titanic.csv')
is.na(df['pclass'])
df[is.na(df['pclass']),]
df <- df[-1310,]
df[is.na(df['fare']),]
df <- df[-1226,]
fixed.ages <- impute_age(df$age, df$pclass)
df <- subset(df, select = -c(name, body, boat, home.dest, cabin, ticket))
df$sex <- factor(df$sex)
df$sex <- as.numeric(df$sex)
df$sex[df$sex == 1] <- 0
df$sex[df$sex == 2] <- 1
df$embarked <- factor(df$embarked)
df$embarked <- factor(df$embarked)
df[,170]
df[170,]
df[df$embarked == "", ]
df<- df[-c(169, 285), ]
df$embarked <- factor(df$embarked)
ifelse(df$embarked == "C", 1, 0)
df$SFlag <- ifelse(df$embarked == "C", 1, 0)
df$SFlag <- ifelse(df$embarked == "S", 1, 0)
df$CFlag <- ifelse(df$embarked == "C", 1, 0)
df$QFlag <- ifelse(df$embarked == "Q", 1, 0)
df <- df[,-8]
# EDA
# Create whatever visualizations you are interested in.
# the data isn't easily interpretable since its just statistical info on images.
pairs(df)
# Train Test Split
# Use the caTools library to split the data into training and testing sets.
library(caTools)
library(dplyr)
split = sample.split(df$variance, SplitRatio = 0.70)
split = sample.split(df$age, SplitRatio = 0.70)
train = subset(df, split == TRUE)
test = subset(df, split == FALSE)
# Building the Neural Net
# Call the neuralnet library
library(neuralnet)
# Use the neuralnet function to train a neural net, set linear.output=FALSe and choose
# 10 hidden neurons (hidden=10)
n <- names(train)
n
# Paste together
f <- as.formula(paste("survived ~", paste(n[!n %in% "survived"], collapse = " + ")))
f
net <- neuralnet(f, data=train, hidden=10, linear.output = FALSE)
# Predictions
# Use compute() to grab predictions useing your nn model on the test set.
predictions <- compute(net, test[, -2])
# Check the head of the predicted values. You should notice that they are still probabilities.
head(predictions)
predictions$net.result
anyNA(df)
which(is.na(df), arr.ind=TRUE)
fixed.ages <- impute_age(df$age, df$pclass)
which(is.na(df), arr.ind=TRUE)
df$age <- fixed.ages
which(is.na(df), arr.ind=TRUE)
split = sample.split(df$age, SplitRatio = 0.70)
train = subset(df, split == TRUE)
test = subset(df, split == FALSE)
# Use the neuralnet function to train a neural net, set linear.output=FALSe and choose
# 10 hidden neurons (hidden=10)
n <- names(train)
n
# Paste together
f <- as.formula(paste("survived ~", paste(n[!n %in% "survived"], collapse = " + ")))
f
net <- neuralnet(f, data=train, hidden=10, linear.output = FALSE)
# Predictions
# Use compute() to grab predictions useing your nn model on the test set.
predictions <- compute(net, test[, -2])
predictions$net.result
# Check the head of the predicted values. You should notice that they are still probabilities.
head(predictions)
predictions <- predictions$net.result
predictions <- data.frame(predictions)
# Apply the round function to the predicted values so you only 0s and 1s as your predicted classes.
predictions <- apply(predictions, 1, round)
# Use table() to create a confusion matrix of your predictions versus the real values
table(predictions, test$survived)
# Comparing Models
# Call the randomForest library
library(randomForest)
# set the Class column of the data as a factor (randomForest needs it to be a factor,
# not an int like neural nets did. Then re-do the train/test split
test$survived <- factor(test$survived)
# Create a randomForest model with the new adjusted training data.
tree <- randomForest(survived ~ ., data=train)
# Use predict() to get the predicted values from your rf model.
treePredict <- predict(tree, test)
# Use predict() to get the predicted values from your rf model.
treePredict <- predict(tree, test, type = "class")
treePredict <- apply(data.frame(treePredict), 1, round)
# Use table() to create the confusion matrix.
table(treePredict, test$class)
# Use table() to create the confusion matrix.
table(treePredict, test$survived)
